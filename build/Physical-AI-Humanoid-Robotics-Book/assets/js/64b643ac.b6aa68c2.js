"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[194],{4368:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"appendices/appendix-a","title":"Appendix A: RAG Chatbot Setup","description":"Complete guide to setting up a Retrieval-Augmented Generation (RAG) chatbot for this textbook using Qdrant and Ollama.","source":"@site/docs/appendices/appendix-a.mdx","sourceDirName":"appendices","slug":"/appendices/appendix-a","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/appendices/appendix-a","draft":false,"unlisted":false,"editUrl":"https://github.com/Danishhshahid/docs/appendices/appendix-a.mdx","tags":[],"version":"current","frontMatter":{"id":"appendix-a","title":"Appendix A: RAG Chatbot Setup","sidebar_label":"Appendix A: RAG Setup","description":"Complete guide to setting up a Retrieval-Augmented Generation (RAG) chatbot for this textbook using Qdrant and Ollama."},"sidebar":"tutorialSidebar","previous":{"title":"Ch6: AI-Robot Pipeline","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/chapters/ch6-capstone"},"next":{"title":"Appendix B: Deployment","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/appendices/appendix-b"}}');var s=t(4848),o=t(8453);const i={id:"appendix-a",title:"Appendix A: RAG Chatbot Setup",sidebar_label:"Appendix A: RAG Setup",description:"Complete guide to setting up a Retrieval-Augmented Generation (RAG) chatbot for this textbook using Qdrant and Ollama."},a=void 0,c={},d=[{value:"Appendix A: RAG Chatbot Setup",id:"appendix-a-rag-chatbot-setup",level:2},{value:"What is RAG?",id:"what-is-rag",level:3},{value:"Architecture",id:"architecture",level:3},{value:"Components",id:"components",level:3},{value:"Setup: Step-by-Step",id:"setup-step-by-step",level:3},{value:"Step 1: Install Qdrant (Vector Database)",id:"step-1-install-qdrant-vector-database",level:4},{value:"Step 2: Prepare Textbook Embeddings",id:"step-2-prepare-textbook-embeddings",level:4},{value:"Step 3: Build RAG API",id:"step-3-build-rag-api",level:4},{value:"Step 4: React Component for Docusaurus",id:"step-4-react-component-for-docusaurus",level:4},{value:"Deployment",id:"deployment",level:3},{value:"Troubleshooting",id:"troubleshooting",level:3}];function l(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"appendix-a-rag-chatbot-setup",children:"Appendix A: RAG Chatbot Setup"}),"\n",(0,s.jsxs)(n.p,{children:["This appendix shows how to build a ",(0,s.jsx)(n.strong,{children:"Retrieval-Augmented Generation (RAG) chatbot"}),' that answers questions about this textbook. Users can ask "How do I compute forward kinematics?" and the chatbot retrieves relevant sections and generates answers using Llama 3.']}),"\n",(0,s.jsx)(n.h3,{id:"what-is-rag",children:"What is RAG?"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"RAG"})," (Retrieval-Augmented Generation) = Search + Generation"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Retrieval"}),": Find relevant textbook sections using semantic search"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Augmentation"}),": Add retrieved sections to the LLM prompt"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Generation"}),": LLM generates answer with textbook context"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Advantage"}),": Answers are grounded in the textbook, not hallucinated."]}),"\n",(0,s.jsx)(n.h3,{id:"architecture",children:"Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:'graph LR\n    User["\ud83d\udc64 User Query<br/>(What is kinematics?)"]\n    Encode["\ud83d\udd0d Encode Query<br/>(CLIP Text Encoder)<br/>\u2192 512-D vector"]\n    Search["\ud83d\udcda Search Qdrant<br/>(Semantic Search)"]\n    Retrieve["\ud83d\udcc4 Retrieved Sections<br/>(Top 3)"]\n    Prompt["\ud83d\udcdd Augment Prompt<br/>(Query + Context)"]\n    LLM["\ud83e\udde0 Llama 3<br/>(Generate Answer)"]\n    Response["\ud83d\udcac Response<br/>(Grounded in textbook)"]\n\n    User --\x3e Encode\n    Encode --\x3e Search\n    Search --\x3e Retrieve\n    Retrieve --\x3e Prompt\n    Prompt --\x3e LLM\n    LLM --\x3e Response\n'})}),"\n",(0,s.jsx)(n.h3,{id:"components",children:"Components"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Component"}),(0,s.jsx)(n.th,{children:"Purpose"}),(0,s.jsx)(n.th,{children:"Technology"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Document Storage"})}),(0,s.jsx)(n.td,{children:"Store textbook sections"}),(0,s.jsx)(n.td,{children:"PostgreSQL or in-memory"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Vector Database"})}),(0,s.jsx)(n.td,{children:"Semantic search"}),(0,s.jsx)(n.td,{children:"Qdrant"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Embedding Model"})}),(0,s.jsx)(n.td,{children:"Convert text \u2192 vectors"}),(0,s.jsx)(n.td,{children:"CLIP ViT-B/32 or Sentence-BERT"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"LLM"})}),(0,s.jsx)(n.td,{children:"Generate answers"}),(0,s.jsx)(n.td,{children:"Llama 3 (via Ollama)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"API"})}),(0,s.jsx)(n.td,{children:"User interface"}),(0,s.jsx)(n.td,{children:"FastAPI (Python) or Node.js"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Frontend"})}),(0,s.jsx)(n.td,{children:"Web UI"}),(0,s.jsx)(n.td,{children:"React component for Docusaurus"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"setup-step-by-step",children:"Setup: Step-by-Step"}),"\n",(0,s.jsx)(n.h4,{id:"step-1-install-qdrant-vector-database",children:"Step 1: Install Qdrant (Vector Database)"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Option A: Docker (Recommended)"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant:latest\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Option B: Local Installation"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# macOS\nbrew install qdrant\n\n# Linux\ncurl https://qdrant.io/install.sh | sh\n\n# Start server\nqdrant_server\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Verify: ",(0,s.jsx)(n.a,{href:"http://localhost:6333",children:"http://localhost:6333"})]}),"\n",(0,s.jsx)(n.h4,{id:"step-2-prepare-textbook-embeddings",children:"Step 2: Prepare Textbook Embeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Script: ",(0,s.jsx)(n.code,{children:"ingest_docs.py"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\nimport json\nimport numpy as np\nfrom pathlib import Path\nimport clip\nimport torch\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\nimport re\n\nclass TextbookIngester:\n    """Extract and embed textbook chapters into Qdrant."""\n\n    def __init__(self, qdrant_url: str = "http://localhost:6333"):\n        self.client = QdrantClient(url=qdrant_url)\n        self.model, self.preprocess = clip.load("ViT-B/32", device="cuda")\n        self.model.eval()\n        self.collection_name = "textbook"\n\n    def create_collection(self):\n        """Create Qdrant collection."""\n        self.client.recreate_collection(\n            collection_name=self.collection_name,\n            vectors_config=VectorParams(size=512, distance=Distance.COSINE)\n        )\n        print(f"\u2713 Created collection: {self.collection_name}")\n\n    def split_into_sections(self, text: str, max_chars: int = 2000) -> list:\n        """Split text into overlapping sections."""\n        sections = []\n        sentences = re.split(r\'(?<=[.!?])\\s+\', text)\n\n        current_section = ""\n        for sentence in sentences:\n            if len(current_section) + len(sentence) < max_chars:\n                current_section += sentence + " "\n            else:\n                if current_section:\n                    sections.append(current_section.strip())\n                current_section = sentence + " "\n\n        if current_section:\n            sections.append(current_section.strip())\n\n        return sections\n\n    @torch.no_grad()\n    def embed_text(self, text: str) -> np.ndarray:\n        """Encode text to 512-D vector."""\n        tokens = clip.tokenize(text[:76]).cuda()  # CLIP max token length\n        embedding = self.model.encode_text(tokens)\n        embedding = embedding / embedding.norm(dim=-1, keepdim=True)\n        return embedding.cpu().numpy()[0]\n\n    def ingest_chapter(self, chapter_path: str, chapter_name: str):\n        """Read chapter .mdx file and ingest sections."""\n\n        with open(chapter_path, \'r\') as f:\n            content = f.read()\n\n        # Strip frontmatter\n        if content.startswith(\'---\'):\n            _, _, content = content.split(\'---\', 2)\n\n        # Split into sections\n        sections = self.split_into_sections(content)\n\n        points = []\n        for i, section in enumerate(sections):\n            # Skip very short sections\n            if len(section) < 100:\n                continue\n\n            section_id = hash(section) % (2**31)  # Unique ID\n            embedding = self.embed_text(section)\n\n            point = PointStruct(\n                id=section_id,\n                vector=embedding.tolist(),\n                payload={\n                    "chapter": chapter_name,\n                    "section_num": i,\n                    "text": section[:1000],  # Store first 1000 chars\n                    "full_text": section\n                }\n            )\n            points.append(point)\n\n        # Upload batch to Qdrant\n        self.client.upsert(\n            collection_name=self.collection_name,\n            points=points\n        )\n        print(f"\u2713 Ingested {len(points)} sections from {chapter_name}")\n\n    def ingest_all_chapters(self, chapters_dir: str):\n        """Process all chapters."""\n        self.create_collection()\n\n        chapter_files = sorted(Path(chapters_dir).glob("ch*.mdx"))\n\n        for chapter_path in chapter_files:\n            chapter_name = chapter_path.stem\n            print(f"\\nProcessing {chapter_name}...")\n            self.ingest_chapter(str(chapter_path), chapter_name)\n\n        print(f"\\n\u2705 All chapters ingested: {len(chapter_files)} chapters")\n\n# Run ingestion\nif __name__ == "__main__":\n    ingester = TextbookIngester()\n    ingester.ingest_all_chapters("./website/docs/chapters/")\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Run it:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 ingest_docs.py\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will ingest all chapters into Qdrant. Check: ",(0,s.jsx)(n.a,{href:"http://localhost:6333/dashboard",children:"http://localhost:6333/dashboard"})," (Qdrant admin UI)."]}),"\n",(0,s.jsx)(n.h4,{id:"step-3-build-rag-api",children:"Step 3: Build RAG API"}),"\n",(0,s.jsxs)(n.p,{children:["Script: ",(0,s.jsx)(n.code,{children:"rag_api.py"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport clip\nimport torch\nimport numpy as np\nfrom qdrant_client import QdrantClient\nimport requests\nimport json\n\napp = FastAPI()\n\n# Initialize\nmodel, preprocess = clip.load("ViT-B/32", device="cuda")\nmodel.eval()\nqdrant_client = QdrantClient(url="http://localhost:6333")\n\nclass QueryRequest(BaseModel):\n    query: str\n\nclass QueryResponse(BaseModel):\n    query: str\n    answer: str\n    sources: list\n\n@app.post("/query", response_model=QueryResponse)\nasync def query_rag(req: QueryRequest):\n    """Query the RAG system."""\n\n    # Step 1: Embed query\n    query_tokens = clip.tokenize(req.query[:76]).cuda()\n    with torch.no_grad():\n        query_embedding = model.encode_text(query_tokens)\n        query_embedding = query_embedding / query_embedding.norm(dim=-1, keepdim=True)\n\n    query_vector = query_embedding.cpu().numpy()[0].tolist()\n\n    # Step 2: Search Qdrant\n    try:\n        search_results = qdrant_client.search(\n            collection_name="textbook",\n            query_vector=query_vector,\n            limit=3  # Top 3 results\n        )\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")\n\n    # Step 3: Extract context\n    context = "\\n\\n".join([\n        result.payload["full_text"]\n        for result in search_results\n    ])\n\n    sources = [\n        {\n            "chapter": result.payload["chapter"],\n            "score": result.score,\n            "excerpt": result.payload["text"][:200]\n        }\n        for result in search_results\n    ]\n\n    # Step 4: Augment prompt\n    prompt = f"""You are an expert roboticist teaching the "Physical AI & Humanoid Robotics Essentials" textbook.\n\nUSER QUESTION: {req.query}\n\nTEXTBOOK CONTEXT:\n{context}\n\nBased on the textbook context above, provide a clear, concise answer. Cite specific sections if relevant."""\n\n    # Step 5: Generate answer with Llama 3\n    response = requests.post(\n        "http://localhost:11434/api/generate",\n        json={\n            "model": "llama3",\n            "prompt": prompt,\n            "stream": False,\n            "temperature": 0.3\n        }\n    )\n\n    if response.status_code != 200:\n        raise HTTPException(status_code=500, detail="LLM error")\n\n    answer = response.json()["response"]\n\n    return QueryResponse(\n        query=req.query,\n        answer=answer,\n        sources=sources\n    )\n\n@app.get("/health")\nasync def health():\n    return {"status": "ok"}\n\nif __name__ == "__main__":\n    import uvicorn\n    uvicorn.run(app, host="0.0.0.0", port=8004)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Run it:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 rag_api.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"Test:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:8004/query \\\n  -H "Content-Type: application/json" \\\n  -d \'{"query": "How do I compute forward kinematics?"}\'\n'})}),"\n",(0,s.jsx)(n.h4,{id:"step-4-react-component-for-docusaurus",children:"Step 4: React Component for Docusaurus"}),"\n",(0,s.jsxs)(n.p,{children:["Create: ",(0,s.jsx)(n.code,{children:"website/src/components/RagQuery.js"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-jsx",children:"import React, { useState } from 'react';\n\nexport default function RagQuery({ placeholder = \"Ask a question...\" }) {\n  const [query, setQuery] = useState('');\n  const [answer, setAnswer] = useState('');\n  const [sources, setSources] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    setLoading(true);\n    setError(null);\n\n    try {\n      const response = await fetch('/api/query', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ query })\n      });\n\n      if (!response.ok) throw new Error('RAG query failed');\n\n      const data = await response.json();\n      setAnswer(data.answer);\n      setSources(data.sources);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div style={{ marginTop: '20px', padding: '15px', backgroundColor: '#f5f5f5', borderRadius: '8px' }}>\n      <h4>\ud83d\udcda Ask the Textbook</h4>\n      <form onSubmit={handleSubmit}>\n        <input\n          type=\"text\"\n          value={query}\n          onChange={(e) => setQuery(e.target.value)}\n          placeholder={placeholder}\n          style={{\n            width: '100%',\n            padding: '10px',\n            borderRadius: '4px',\n            border: '1px solid #ccc',\n            marginBottom: '10px'\n          }}\n        />\n        <button type=\"submit\" disabled={loading} style={{ padding: '8px 16px' }}>\n          {loading ? 'Loading...' : 'Search'}\n        </button>\n      </form>\n\n      {error && <p style={{ color: 'red' }}>Error: {error}</p>}\n\n      {answer && (\n        <div style={{ marginTop: '15px' }}>\n          <h5>Answer:</h5>\n          <p>{answer}</p>\n          {sources.length > 0 && (\n            <div>\n              <h6>Sources:</h6>\n              <ul>\n                {sources.map((src, i) => (\n                  <li key={i}>\n                    <strong>{src.chapter}</strong> (score: {src.score.toFixed(2)})\n                    <br />\n                    <em>{src.excerpt}...</em>\n                  </li>\n                ))}\n              </ul>\n            </div>\n          )}\n        </div>\n      )}\n    </div>\n  );\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"Use in Docusaurus pages:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mdx",children:"import RagQuery from '@site/src/components/RagQuery';\n\n<RagQuery placeholder=\"Ask me about humanoid kinematics\" />\n"})}),"\n",(0,s.jsx)(n.h3,{id:"deployment",children:"Deployment"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Docker Compose (Production)"})}),"\n",(0,s.jsxs)(n.p,{children:["Add to ",(0,s.jsx)(n.code,{children:"docker-compose.yml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'qdrant:\n  image: qdrant/qdrant:latest\n  volumes:\n    - qdrant_data:/qdrant/storage\n  ports:\n    - "6333:6333"\n  networks:\n    - robot_network\n\nrag_api:\n  build:\n    context: .\n    dockerfile: Dockerfile.rag\n  depends_on:\n    - qdrant\n    - language  # Ollama service\n  environment:\n    QDRANT_URL: http://qdrant:6333\n    OLLAMA_HOST: http://language:11434\n  ports:\n    - "8004:8004"\n  networks:\n    - robot_network\n'})}),"\n",(0,s.jsx)(n.h3,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Issue"}),(0,s.jsx)(n.th,{children:"Solution"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Qdrant connection refused"}),(0,s.jsxs)(n.td,{children:["Check if Qdrant is running: ",(0,s.jsx)(n.code,{children:"curl http://localhost:6333"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Embedding mismatch"}),(0,s.jsx)(n.td,{children:"Ensure CLIP model and Qdrant vector size match (512)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Slow search"}),(0,s.jsxs)(n.td,{children:["Increase Qdrant ",(0,s.jsx)(n.code,{children:"index_size"})," or use GPU"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"LLM not responding"}),(0,s.jsxs)(n.td,{children:["Verify Ollama is running: ",(0,s.jsx)(n.code,{children:"ollama pull llama3"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"React component not loading"}),(0,s.jsxs)(n.td,{children:["Rebuild Docusaurus: ",(0,s.jsx)(n.code,{children:"npm run build"})]})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Next"}),": ",(0,s.jsx)(n.a,{href:"/docs/appendix-b",children:"Appendix B: Free-Tier Deployment \u2192"})]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var r=t(6540);const s={},o=r.createContext(s);function i(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);