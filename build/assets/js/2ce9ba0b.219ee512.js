"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[521],{2775:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"modules/m2-digital-twin/m2-unity-rendering","title":"Lesson 2: Unity Rendering & Visualization","description":"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control.","source":"@site/docs/modules/m2-digital-twin/m2-unity-rendering.mdx","sourceDirName":"modules/m2-digital-twin","slug":"/modules/m2-digital-twin/m2-unity-rendering","permalink":"/docs/modules/m2-digital-twin/m2-unity-rendering","draft":false,"unlisted":false,"editUrl":"https://github.com/Danishhshahid/Physical-AI-Humanoid-Robotics-Book/tree/main/website/docs/modules/m2-digital-twin/m2-unity-rendering.mdx","tags":[],"version":"current","frontMatter":{"id":"m2-unity-rendering","title":"Lesson 2: Unity Rendering & Visualization","sidebar_label":"L2: Unity Rendering","description":"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control."},"sidebar":"tutorialSidebar","previous":{"title":"L1: Gazebo Physics","permalink":"/docs/modules/m2-digital-twin/m2-gazebo-physics"},"next":{"title":"L3: Sensor Simulation","permalink":"/docs/modules/m2-digital-twin/m2-sensor-simulation"}}');var r=i(4848),o=i(8453);const a={id:"m2-unity-rendering",title:"Lesson 2: Unity Rendering & Visualization",sidebar_label:"L2: Unity Rendering",description:"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control."},s=void 0,l={},d=[{value:"Why Unity for Visualization?",id:"why-unity-for-visualization",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Setting Up Unity with ROS 2",id:"setting-up-unity-with-ros-2",level:2},{value:"Install ROS 2 for Unity",id:"install-ros-2-for-unity",level:3},{value:"Export Robot Model to FBX",id:"export-robot-model-to-fbx",level:3},{value:"Real-Time Camera Streaming",id:"real-time-camera-streaming",level:2},{value:"Visualizing Trajectories",id:"visualizing-trajectories",level:2},{value:"Interactive Teleoperation",id:"interactive-teleoperation",level:2},{value:"Lighting &amp; Materials",id:"lighting--materials",level:2},{value:"Hands-On Project",id:"hands-on-project",level:2},{value:"Next Lesson",id:"next-lesson",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"why-unity-for-visualization",children:"Why Unity for Visualization?"}),"\n",(0,r.jsxs)(n.p,{children:["Gazebo provides physics but limited visual fidelity. ",(0,r.jsx)(n.strong,{children:"Unity"})," excels at:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfa8 ",(0,r.jsx)(n.strong,{children:"Photorealistic rendering"}),": High-quality graphics, realistic materials"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfae ",(0,r.jsx)(n.strong,{children:"Real-time interaction"}),": Teleoperation dashboards"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udce1 ",(0,r.jsx)(n.strong,{children:"Data visualization"}),": Live sensor streams, planning visualization"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83e\udd16 ",(0,r.jsx)(n.strong,{children:"Human-robot interaction"}),": Show robot capabilities to stakeholders"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Modern robots stream their state from ROS 2 to Unity for rich visualization."}),"\n",(0,r.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Gazebo (Physics) \u2194 ROS 2 \u2194 Unity (Rendering)\n\u251c\u2500 Robot state (poses)\n\u251c\u2500 Sensor data (camera feeds, IMU)\n\u2514\u2500 Planned trajectories\n"})}),"\n",(0,r.jsx)(n.h2,{id:"setting-up-unity-with-ros-2",children:"Setting Up Unity with ROS 2"}),"\n",(0,r.jsx)(n.h3,{id:"install-ros-2-for-unity",children:"Install ROS 2 for Unity"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install ROS-TCP-Connector (bridges ROS 2 to Unity)\ngit clone https://github.com/RoboticsToolkit/ros2-for-unity.git\n"})}),"\n",(0,r.jsx)(n.h3,{id:"export-robot-model-to-fbx",children:"Export Robot Model to FBX"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Export from CAD \u2192 URDF \u2192 FBX format"}),"\n",(0,r.jsx)(n.li,{children:"Import FBX into Unity"}),"\n",(0,r.jsx)(n.li,{children:"Attach ROS 2 bridge scripts"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"real-time-camera-streaming",children:"Real-Time Camera Streaming"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\nusing ROS2;\n\npublic class CameraStreamer : MonoBehaviour {\n    private ROS2Node ros2Node;\n    private ISubscription<ROS2.Sensor.Image> cameraSubscription;\n    private Texture2D cameraTexture;\n\n    void Start() {\n        ros2Node = GetComponent<ROS2Node>();\n\n        // Subscribe to camera feed\n        cameraSubscription = ros2Node.CreateSubscription<ROS2.Sensor.Image>(\n            "/camera/image",\n            OnCameraFrame\n        );\n\n        cameraTexture = new Texture2D(640, 480, TextureFormat.RGB24, false);\n    }\n\n    void OnCameraFrame(ROS2.Sensor.Image msg) {\n        // Convert ROS Image to Unity Texture\n        cameraTexture.LoadRawTextureData(msg.data);\n        cameraTexture.Apply();\n\n        // Display on canvas\n        GetComponent<RawImage>().texture = cameraTexture;\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"visualizing-trajectories",children:"Visualizing Trajectories"}),"\n",(0,r.jsx)(n.p,{children:"Show planned robot trajectories in real-time:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"using UnityEngine;\nusing ROS2.TrajectoryMsgs;\n\npublic class TrajectoryVisualizer : MonoBehaviour {\n    public Material trajMaterial;\n    private LineRenderer lineRenderer;\n\n    void OnTrajectoryReceived(JointTrajectory trajectory) {\n        lineRenderer.positionCount = trajectory.points.Count;\n\n        for (int i = 0; i < trajectory.points.Count; i++) {\n            // Convert joint angles to Cartesian position\n            Vector3 position = ComputeForwardKinematics(trajectory.points[i].positions);\n            lineRenderer.SetPosition(i, position);\n        }\n    }\n\n    Vector3 ComputeForwardKinematics(double[] jointAngles) {\n        // Implement FK or call ROS 2 service\n        // ...\n        return Vector3.zero;\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"interactive-teleoperation",children:"Interactive Teleoperation"}),"\n",(0,r.jsx)(n.p,{children:"Create a UI for manual robot control:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class TeleoperationPanel : MonoBehaviour {\n    private ROS2Node ros2Node;\n\n    void Update() {\n        // Read slider values (0-1 range for each joint)\n        float shoulderAngle = GetSliderValue("shoulder");\n        float elbowAngle = GetSliderValue("elbow");\n\n        if (Input.GetButtonDown("Submit")) {\n            SendJointCommand(new[] { shoulderAngle, elbowAngle });\n        }\n    }\n\n    void SendJointCommand(float[] angles) {\n        // Convert to ROS message and publish\n        var cmd = new JointTrajectory() {\n            JointNames = new[] { "shoulder", "elbow" },\n            // ...\n        };\n\n        ros2Node.Publish("/arm/commands", cmd);\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"lighting--materials",children:"Lighting & Materials"}),"\n",(0,r.jsx)(n.p,{children:"Use physically-based materials for realism:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'Material metal = new Material(Shader.Find("Standard"));\nmetal.SetFloat("_Metallic", 1.0f);\nmetal.SetFloat("_Glossiness", 0.8f);\n\nMaterial rubber = new Material(Shader.Find("Standard"));\nrubber.SetFloat("_Metallic", 0.0f);\nrubber.SetFloat("_Glossiness", 0.2f);\n'})}),"\n",(0,r.jsx)(n.h2,{id:"hands-on-project",children:"Hands-On Project"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Export your humanoid arm model to FBX"}),"\n",(0,r.jsx)(n.li,{children:"Import into Unity"}),"\n",(0,r.jsxs)(n.li,{children:["Create a dashboard showing:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Live camera feed"}),"\n",(0,r.jsx)(n.li,{children:"Current joint angles"}),"\n",(0,r.jsx)(n.li,{children:"Planned trajectory visualization"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Add interactive sliders to control joint angles in real-time"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-lesson",children:"Next Lesson"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"/docs/modules/m2-digital-twin/m2-sensor-simulation",children:"Lesson 3: Sensor Simulation"})})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>s});var t=i(6540);const r={},o=t.createContext(r);function a(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);